TdBench for Teradata Vantage Lake Edition:

Current version of the Teradata JDBC jar file can be downloaded from developer.teradata.com.
While a version was included with tdbench as a convenience, you should check for later versions.
(FYI: with Teradata JDBC version 16.20.00.12, the /tdgssconfig.jar is no longer used, only
terajdbc4.jar is needed)

It is recommended that you define the JDBC driver and database login information in the
tdbench.tdb file which is processed everytime TdBench starts.  This is done with the
CLASS and DB statements. An example of the CLASS and DB alias statements is:

   class com.teradata.jdbc.TeraDriver jdbc:teradata terajdbc4.jar 
   db tdprod jdbc:teradata://10.25.11.107 MyUser Xpassword123

The syntax of the TdBench class statement is:
   CLASS   [class-name-of-JDBC-driver] [URL-of-JDBC-driver] [file-name(s)-of-JDBC-driver-jar]

In the example CLASS statement, the JDBC jar file was located in the home directory 
where TdBench was installed.  On your PC, you may want to have a "java" directory somewhere
containing downloaded jar files that you use across JAVA applications.

The syntax of the DB statement is:
   DB  [db-alias-name] [URL-of-JDBC-driver:dbms-address] {username {password}} 

The db-alias-name may be anything you want to use on the WORKER, SQL, or BEFORE_RUN/AFTER_RUN
statements. The second parameter references the URL of the JDBC driver and provides either
the IP address or DNS name to connect to your DBMS platform. Finally, you can specify a username
and password. The WORKER statement allows you to over-ride the Username and specify a username
pattern for using multiple logon IDs for a test. This can prevent issues exceeding spool where 
one worker with heavy spool usage or skewed spool causes other sessions to fail. 

You can follow the dbms-address with a / and additional parameters, separated by comma. Some 
examples are:
   ACCOUNT=account-name ... account to be charged with usage
   CHARSET=charset-name ... examples: ASCII, UTF8, UTF16
   DATABASE=database-name ... default database
   LOG=option ... ERROR is default. Other options: INFO and DEBUG
   NEW_PASSWORD=password ... will change password, but only 1 session is allowed
   TMODE=option ... transaction mode: ANSI or TERADATA

Example:
   db tdprod jdbc:teradata://10.25.11.107/DATABASE=MyDB,TMODE=ANSI MyUser Xpassword123

See Teradata JDBC Driver User Guide for additional parameter information.

TdBench can manage reporting against the Teradata host DBMS Database Query Logging (DBQL) and
ResUsage tables. This requires telling TdBench to run host database commands before and
after each test run.  The following 

   before_run sql tdprod exec acme_benchmark.teststart(':testname', ':testdescription',  , :runid);
   after_run sql tdprod exec acme_benchmark.teststop(,, :resultcount, :errorcount);

The BEFORE_RUN command specifies the SQL to execute immediately before the RUN statement is processed.
For Teradata, not only does it create a row in the host DBMS benchmark TestTracking table with the 
CURRENT_TIMESTAMP, but it collects information about the current hardware, software, and TASM
configuration as well as competing workload (that is, logon ID's that don't begin with the 
defined prefix for the benchmark). 

The AFTER_RUN command specifies the SQL to execute immediately after the RUN statement completes.
This updates the ActualStopTime in the host DBMS benchmark TestTracking table along with the 
completions as viewed by the client TdBench application. The precise host DBMS StartTime and
ActualStopTime for each test in the TestTracking table allows joining that to the DBQL and
ResUsage tables to select data for one RunID or for several RunID's that you want to compare.
This is important because the clock of the host DBMS may be in a different timezone than 
the client PC where TdBench is running.

There is a RunID assigned by the TdBench application and stored in its internal H2 database
and a RunID assigned by the TestStart macro. These will not be the same, especially when some
tests are being run by an instance of TdBench running on Linux (workload tests, data loading)
and some tests are being run by an instance of TdBench running on Windows (initiating BI tools).
The RunID generated by TdBench is passed on the TestStart macro and saved in the host DBMS
TestTracking table as ClientRunID. 

To set up host DBMS reporting, you will need to create a benchmark user on the DBMS for holding test 
metadata, macros, functions and reporting views against DBQL and Resusage tables in DBC and TD_METRIC_SVC. 
Note:  Grants may need to be executed from DBC to get all rights specified below.

Allocate 50 MB to the user and grant:
   grant all on xxx_benchmark to xxx_benchmark with grant option;
   grant select on TD_METRIC_SVC to acme_benchmark with grant option;
   grant select, execute on dbc to xxx_benchmark with grant option;
   grant exec function on syslib to xxx_benchmark with grant option;
   grant exec function, select on tdwm to xxx_benchmark with grant option;

Where xxx is a prefix for the customer or engagement. Then use the setup option:
   2 - edit variables for your DBMS query logging setup

to add logon and database information needed by the setup scripts. The tdbench_teradata_lake_config.tdb
file has comments describing the fields you need to update. The field TdBenchPrefix should
be the same as the prefix used for the customer or engagement that you used to create the Benchmark 
user. That prefix will be used in reporting views to distinguish benchmark usage versus competing 
workload. If you create additional user names for your tests, use that same prefix for those user names.

Setup option 3 can be used to validate the rights and setup of the host DBMS user, then
option 4 will run setup/teradata/setup_dbms.tdb to setup tables, functions, macros and
reporting views.  Alternatively, under tdbench issue: 

                include setup/teradata_lake/setup_dbms.tdb

IT IS RECOMMENDED if you modify views or macros that you create alias named versions so that
you can overlay the installation with new releases and not lose your changes. 

There is a TdBench Excel reporting template on developer.teradata.com that you can use to reference 
the reporting views, or just issue selects against the views with a constraint against RunID. 

There is a set of base level views with names identical to the DBQL and Resusage views in 
TD_Metric_SVC but extended with information joined from the TestTracking table. This allows
easy selection of test results by RunID. 

For the Vantage Lake edition, there is also a TestTrackingV view that has a subset of the TestTracking
table columns but adds the column Where_Clause which contains the constraints that can be used for
path filtering from TD_Metric_SVC and benchmark semantic reporting views. The use of those constraints
in your queries will reduce the number of files on the cloud that are opened to find the results
from your tests. Example of the generated path filtering in the Where_Clause column:
    PATH_YEAR='2024' and PATH_MONTH='03' and PATH_DAY='28'

The semantic reporting views provide a useful subset of TD_Metric_SVC views, add additional calculations, 
and also expose the path variables for filtering. The Rpt_Sum_Runs also creates a Where_Clause column to
use in building queries against other RPT_ ... views. 

TD_Metric_SVC is gathering DBQL and Resusage data from multiple clusters.  Even if you issue:
"flush query logging with all" to cause the DBQL buffers to be written, it could take minutes for the
results of your test to show up in reporting views. The DBQLogV in TD_Metric_SVC could have multiple
rows for a query since the execution of the query could occur on the primary and a compute cluster. 
The view DBQLogV in Td_Metric_SVC is summarized with the benchmark view DBQLogV_sum to get 1 row per 
query and then that view is joined to the TestTracking table to create DBQLogV with the added
columns to allow selection of the results from a particular RunID. (Note that views on views on views
adds very slightly to parsing time but no impact to execution time).  

Reporting performance for DBQL and Resusage data on Teradata Vantage Lake Edition will be slower
than for Teradata Vantage Enterprise edition since data is in multiple files on cloud storage versus
local tables in DBC and PDCR. Usage of the path filtering constraints is critical to improving
performance. Performance will be better for prior days than the current day due to consolidation 
of logging files on the cloud  at the end of each day. 
